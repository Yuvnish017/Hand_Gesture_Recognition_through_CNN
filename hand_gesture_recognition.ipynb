{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "hand_gesture_recognition.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JdZSHMiy3a9z"
      },
      "source": [
        "import numpy\n",
        "import cv2 as cv\n",
        "from keras.layers import Input, Conv2D, Activation, MaxPool2D, Flatten, Dense\n",
        "from keras.models import Model\n",
        "from keras.regularizers import l2\n",
        "from keras.initializers import glorot_uniform\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0r_4tDb8J0O"
      },
      "source": [
        "def convert_to_one_hot(v, c):\n",
        "    v = numpy.eye(c)[v.reshape(-1)]\n",
        "    return v"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O3Su-deL46uV",
        "outputId": "27c42220-fbe9-483d-9c6a-7c0e14c3d335"
      },
      "source": [
        "X_train = []\n",
        "Y_train = []\n",
        "X_test = []\n",
        "Y_test = []\n",
        "\n",
        "with open('/content/drive/MyDrive/train_dataset.csv', 'r') as f:\n",
        "  reader = csv.reader(f)\n",
        "  for row in reader:\n",
        "    if len(row) != 0:\n",
        "      label = row[0]\n",
        "      image = numpy.array([int(i) for i in row[1:]], dtype='uint8')\n",
        "      image = image.reshape((28, 28, 3))\n",
        "      image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
        "      image = cv.resize(image, (125, 125))\n",
        "      X_train.append(image)\n",
        "      Y_train.append(label)\n",
        "\n",
        "print('len of X_train: ', len(X_train))\n",
        "print('len of Y_train: ', len(Y_train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "len of X_train:  62400\n",
            "len of Y_train:  62400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZnaXssI6b3B",
        "outputId": "ae5c569a-5952-432e-9079-b66bf3186cc1"
      },
      "source": [
        "with open('/content/drive/MyDrive/test_dataset.csv', 'r') as f:\n",
        "  reader = csv.reader(f)\n",
        "  for row in reader:\n",
        "    if len(row) == 2353:\n",
        "      label = row[0]\n",
        "      image = numpy.array([int(i) for i in row[1:]], dtype='uint8')\n",
        "      image = image.reshape((28, 28, 3))\n",
        "      image = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\n",
        "      image = cv.resize(image, (125, 125))\n",
        "      X_test.append(image)\n",
        "      Y_test.append(label)\n",
        "\n",
        "print('len of X_test: ', len(X_test))\n",
        "print('len of Y_test: ', len(Y_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "len of X_test:  14999\n",
            "len of Y_test:  14999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4u0TiM88TPc",
        "outputId": "d125739d-8f92-494d-ffcf-d65f86b13a7d"
      },
      "source": [
        "X_train = numpy.array(X_train)\n",
        "X_test = numpy.array(X_test)\n",
        "Y_train = numpy.array(Y_train)\n",
        "Y_test = numpy.array(Y_test)\n",
        "print(X_train.shape)\n",
        "print(Y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(Y_test.shape)\n",
        "\n",
        "X_train = numpy.expand_dims(X_train, axis=-1)\n",
        "Y_train = to_categorical(Y_train, num_classes=26)\n",
        "\n",
        "X_test = numpy.expand_dims(X_test, axis=-1)\n",
        "Y_test = to_categorical(Y_test, num_classes=26)\n",
        "\n",
        "print('shape of X_train: ', X_train.shape)\n",
        "print('shape of Y_train: ', Y_train.shape)\n",
        "print('shape of X_test: ', X_test.shape)\n",
        "print('shape of Y_test: ', Y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(62400, 125, 125)\n",
            "(62400,)\n",
            "(14999, 125, 125)\n",
            "(14999,)\n",
            "shape of X_train:  (62400, 125, 125, 1)\n",
            "shape of Y_train:  (62400, 26)\n",
            "shape of X_test:  (14999, 125, 125, 1)\n",
            "shape of Y_test:  (14999, 26)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Db-2xFld_GfE"
      },
      "source": [
        "def hand_gesture_recognition(input_shape=(125, 125, 1), classes=26):\n",
        "  X_input = Input(shape=input_shape)\n",
        "  X = Conv2D(32, (3, 3), strides=(1, 1), padding='same', name='conv1', kernel_initializer=glorot_uniform(seed=0), kernel_regularizer=l2(0.0001))(X_input)\n",
        "  X = Conv2D(32, (8, 8), strides=(1, 1), padding='same', name='conv2', kernel_initializer=glorot_uniform(seed=0), kernel_regularizer=l2(0.0001))(X)\n",
        "  X = Activation(activation='relu')(X)\n",
        "  X = MaxPool2D((2,2), strides=(2, 2))(X)\n",
        "  X = Conv2D(64, (8, 8), strides=(1, 1), padding='same', name='conv3', kernel_initializer=glorot_uniform(seed=0), kernel_regularizer=l2(0.0001))(X)\n",
        "  X = Conv2D(32, (8, 8), strides=(1, 1), padding='same', name='conv4', kernel_initializer=glorot_uniform(seed=0), kernel_regularizer=l2(0.0001))(X)\n",
        "  X = Conv2D(64, (2, 2), strides=(1, 1), padding='same', name='conv5', kernel_initializer=glorot_uniform(seed=0), kernel_regularizer=l2(0.0001))(X)\n",
        "  X = Activation(activation='relu')(X)\n",
        "  X = MaxPool2D((2,2), strides=(2, 2))(X)\n",
        "  X = Conv2D(64, (4, 4), strides=(1, 1), padding='same', name='conv6', kernel_initializer=glorot_uniform(seed=0), kernel_regularizer=l2(0.0001))(X)\n",
        "  X = Conv2D(64, (4, 4), strides=(1, 1), padding='same', name='conv7', kernel_initializer=glorot_uniform(seed=0), kernel_regularizer=l2(0.0001))(X)\n",
        "  X = Conv2D(64, (3, 3), strides=(1, 1), padding='same', name='conv8', kernel_initializer=glorot_uniform(seed=0), kernel_regularizer=l2(0.0001))(X)\n",
        "  X = Conv2D(64, (3, 3), strides=(1, 1), padding='same', name='conv9', kernel_initializer=glorot_uniform(seed=0), kernel_regularizer=l2(0.0001))(X)\n",
        "  X = Activation(activation='relu')(X)\n",
        "  X = Flatten()(X)\n",
        "  X = Dense(64, activation='relu', name='fc1', kernel_initializer=glorot_uniform(seed=0), kernel_regularizer=l2(0.0001))(X)\n",
        "  X = Dense(64, activation='relu', name='fc2', kernel_initializer=glorot_uniform(seed=0), kernel_regularizer=l2(0.0001))(X)\n",
        "  X = Dense(classes, activation='softmax', name='fc4', kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "\n",
        "  cnn_model = Model(inputs=X_input, outputs=X, name='hand_gesture_recognition')\n",
        "  return cnn_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0O5TnzXZ74c",
        "outputId": "9d4b05a9-86dc-4374-8fd9-ece9733f4938"
      },
      "source": [
        "aug = ImageDataGenerator(rotation_range=10, width_shift_range=0.1, height_shift_range=0.1, shear_range=0.15, zoom_range=0.05, horizontal_flip=False, fill_mode='nearest')\n",
        "hand_gesture_model = hand_gesture_recognition(input_shape=(125, 125, 1), classes=26)\n",
        "hand_gesture_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "hand_gesture_model.summary()\n",
        "hand_gesture_model.fit(aug.flow(X_train, Y_train, batch_size=1024), epochs=50, batch_size=1024)\n",
        "prediction = hand_gesture_model.evaluate(X_test, Y_test)\n",
        "print('loss on test set: ', prediction[0])\n",
        "print('accuracy on test set: ', prediction[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"hand_gesture_recognition\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 125, 125, 1)]     0         \n",
            "_________________________________________________________________\n",
            "conv1 (Conv2D)               (None, 125, 125, 32)      320       \n",
            "_________________________________________________________________\n",
            "conv2 (Conv2D)               (None, 125, 125, 32)      65568     \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 125, 125, 32)      0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 62, 62, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv3 (Conv2D)               (None, 62, 62, 64)        131136    \n",
            "_________________________________________________________________\n",
            "conv4 (Conv2D)               (None, 62, 62, 32)        131104    \n",
            "_________________________________________________________________\n",
            "conv5 (Conv2D)               (None, 62, 62, 64)        8256      \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 62, 62, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 31, 31, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv6 (Conv2D)               (None, 31, 31, 64)        65600     \n",
            "_________________________________________________________________\n",
            "conv7 (Conv2D)               (None, 31, 31, 64)        65600     \n",
            "_________________________________________________________________\n",
            "conv8 (Conv2D)               (None, 31, 31, 64)        36928     \n",
            "_________________________________________________________________\n",
            "conv9 (Conv2D)               (None, 31, 31, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 31, 31, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 61504)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 64)                3936320   \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "fc4 (Dense)                  (None, 26)                1690      \n",
            "=================================================================\n",
            "Total params: 4,483,610\n",
            "Trainable params: 4,483,610\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/50\n",
            "61/61 [==============================] - 224s 3s/step - loss: 66.9001 - accuracy: 0.0479\n",
            "Epoch 2/50\n",
            "61/61 [==============================] - 184s 3s/step - loss: 2.4400 - accuracy: 0.3280\n",
            "Epoch 3/50\n",
            "61/61 [==============================] - 185s 3s/step - loss: 1.0536 - accuracy: 0.7145\n",
            "Epoch 4/50\n",
            "61/61 [==============================] - 186s 3s/step - loss: 0.5023 - accuracy: 0.8747\n",
            "Epoch 5/50\n",
            "61/61 [==============================] - 186s 3s/step - loss: 0.3245 - accuracy: 0.9261\n",
            "Epoch 6/50\n",
            "61/61 [==============================] - 186s 3s/step - loss: 0.2521 - accuracy: 0.9469\n",
            "Epoch 7/50\n",
            "61/61 [==============================] - 186s 3s/step - loss: 0.2049 - accuracy: 0.9615\n",
            "Epoch 8/50\n",
            "61/61 [==============================] - 186s 3s/step - loss: 0.1713 - accuracy: 0.9723\n",
            "Epoch 9/50\n",
            "61/61 [==============================] - 186s 3s/step - loss: 0.1625 - accuracy: 0.9755\n",
            "Epoch 10/50\n",
            "61/61 [==============================] - 186s 3s/step - loss: 0.1449 - accuracy: 0.9799\n",
            "Epoch 11/50\n",
            "61/61 [==============================] - 187s 3s/step - loss: 0.1260 - accuracy: 0.9866\n",
            "Epoch 12/50\n",
            "61/61 [==============================] - 186s 3s/step - loss: 0.1227 - accuracy: 0.9867\n",
            "Epoch 13/50\n",
            "61/61 [==============================] - 186s 3s/step - loss: 0.1187 - accuracy: 0.9882\n",
            "Epoch 14/50\n",
            "61/61 [==============================] - 186s 3s/step - loss: 0.1146 - accuracy: 0.9892\n",
            "Epoch 15/50\n",
            "61/61 [==============================] - 186s 3s/step - loss: 0.1195 - accuracy: 0.9879\n",
            "Epoch 16/50\n",
            "61/61 [==============================] - 187s 3s/step - loss: 0.1122 - accuracy: 0.9901\n",
            "Epoch 17/50\n",
            "61/61 [==============================] - 186s 3s/step - loss: 0.1108 - accuracy: 0.9901\n",
            "Epoch 18/50\n",
            "61/61 [==============================] - 187s 3s/step - loss: 0.1007 - accuracy: 0.9928\n",
            "Epoch 19/50\n",
            "61/61 [==============================] - 187s 3s/step - loss: 0.0978 - accuracy: 0.9941\n",
            "Epoch 20/50\n",
            "61/61 [==============================] - 187s 3s/step - loss: 0.0972 - accuracy: 0.9940\n",
            "Epoch 21/50\n",
            "61/61 [==============================] - 187s 3s/step - loss: 0.1051 - accuracy: 0.9915\n",
            "Epoch 22/50\n",
            "61/61 [==============================] - 187s 3s/step - loss: 0.0906 - accuracy: 0.9952\n",
            "Epoch 23/50\n",
            "61/61 [==============================] - 186s 3s/step - loss: 0.0943 - accuracy: 0.9943\n",
            "Epoch 24/50\n",
            "61/61 [==============================] - 187s 3s/step - loss: 0.0904 - accuracy: 0.9954\n",
            "Epoch 25/50\n",
            "61/61 [==============================] - 187s 3s/step - loss: 0.0881 - accuracy: 0.9955\n",
            "Epoch 26/50\n",
            "61/61 [==============================] - 187s 3s/step - loss: 0.0937 - accuracy: 0.9937\n",
            "Epoch 27/50\n",
            "61/61 [==============================] - 187s 3s/step - loss: 0.0876 - accuracy: 0.9952\n",
            "Epoch 28/50\n",
            "61/61 [==============================] - 187s 3s/step - loss: 0.0873 - accuracy: 0.9954\n",
            "Epoch 29/50\n",
            "61/61 [==============================] - 187s 3s/step - loss: 0.0872 - accuracy: 0.9957\n",
            "Epoch 30/50\n",
            "61/61 [==============================] - 187s 3s/step - loss: 0.0923 - accuracy: 0.9944\n",
            "Epoch 31/50\n",
            "61/61 [==============================] - 187s 3s/step - loss: 0.0875 - accuracy: 0.9958\n",
            "Epoch 32/50\n",
            "61/61 [==============================] - 186s 3s/step - loss: 0.0863 - accuracy: 0.9953\n",
            "Epoch 33/50\n",
            "61/61 [==============================] - 187s 3s/step - loss: 0.1200 - accuracy: 0.9857\n",
            "Epoch 34/50\n",
            "61/61 [==============================] - 187s 3s/step - loss: 0.0842 - accuracy: 0.9962\n",
            "Epoch 35/50\n",
            "61/61 [==============================] - 187s 3s/step - loss: 0.0828 - accuracy: 0.9968\n",
            "Epoch 36/50\n",
            "61/61 [==============================] - 187s 3s/step - loss: 0.0822 - accuracy: 0.9968\n",
            "Epoch 37/50\n",
            "61/61 [==============================] - 187s 3s/step - loss: 0.0803 - accuracy: 0.9973\n",
            "Epoch 38/50\n",
            "61/61 [==============================] - 187s 3s/step - loss: 0.0795 - accuracy: 0.9970\n",
            "Epoch 39/50\n",
            "61/61 [==============================] - 187s 3s/step - loss: 0.0808 - accuracy: 0.9966\n",
            "Epoch 40/50\n",
            "61/61 [==============================] - 187s 3s/step - loss: 0.0789 - accuracy: 0.9970\n",
            "Epoch 41/50\n",
            "61/61 [==============================] - 187s 3s/step - loss: 0.0801 - accuracy: 0.9968\n",
            "Epoch 42/50\n",
            "61/61 [==============================] - 187s 3s/step - loss: 0.0812 - accuracy: 0.9963\n",
            "Epoch 43/50\n",
            "61/61 [==============================] - 187s 3s/step - loss: 0.0807 - accuracy: 0.9965\n",
            "Epoch 44/50\n",
            "61/61 [==============================] - 187s 3s/step - loss: 0.0815 - accuracy: 0.9960\n",
            "Epoch 45/50\n",
            "61/61 [==============================] - 187s 3s/step - loss: 0.0761 - accuracy: 0.9977\n",
            "Epoch 46/50\n",
            "61/61 [==============================] - 187s 3s/step - loss: 0.0867 - accuracy: 0.9944\n",
            "Epoch 47/50\n",
            "61/61 [==============================] - 187s 3s/step - loss: 0.0787 - accuracy: 0.9971\n",
            "Epoch 48/50\n",
            "61/61 [==============================] - 187s 3s/step - loss: 0.0778 - accuracy: 0.9969\n",
            "Epoch 49/50\n",
            "61/61 [==============================] - 187s 3s/step - loss: 0.0765 - accuracy: 0.9974\n",
            "Epoch 50/50\n",
            "61/61 [==============================] - 187s 3s/step - loss: 0.0826 - accuracy: 0.9959\n",
            "469/469 [==============================] - 10s 20ms/step - loss: 0.0954 - accuracy: 0.9933\n",
            "loss on test set:  0.0954391285777092\n",
            "accuracy on test set:  0.993266224861145\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2aXvHk4a7qA"
      },
      "source": [
        "hand_gesture_model.save('/content/drive/MyDrive/data_augmentation_model_hgr_v3.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gw_WsqMhbu6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}